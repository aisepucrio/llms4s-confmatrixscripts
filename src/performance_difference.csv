model,prompt,metric,raw,clean,difference
DEVA,prompt_base,precision,0.692065732432705,0.6864790363926159,-0.005586696040089101
DEVA,prompt_base,recall,0.6629969418960244,0.6541353383458647,-0.008861603550159747
DEVA,prompt_base,f1-score,0.6674364684871864,0.6586824213678245,-0.008754047119361896
Senti4SD,prompt_base,precision,0.6153946457136662,0.6133009677019723,-0.0020936780116939113
Senti4SD,prompt_base,recall,0.6159021406727829,0.6130711393869288,-0.002831001285854118
Senti4SD,prompt_base,f1-score,0.6106866230088808,0.6078440506005959,-0.0028425724082848935
SentiCR,prompt_base,precision,0.33428183040901016,0.3292308410157559,-0.005050989393254268
SentiCR,prompt_base,recall,0.4801223241590214,0.4719491035280509,-0.008173220630970479
SentiCR,prompt_base,f1-score,0.38480085110027595,0.3800069542941807,-0.004793896806095266
SentiStrength,prompt_base,precision,0.6497641344953344,0.6489883313140217,-0.0007758031813127619
SentiStrength,prompt_base,recall,0.5779816513761468,0.5766338924233662,-0.0013477589527806089
SentiStrength,prompt_base,f1-score,0.5693773732051307,0.5659755397445002,-0.003401833460630499
SentiStrengthSE,prompt_base,precision,0.711515651981928,0.7106887022208834,-0.000826949761044582
SentiStrengthSE,prompt_base,recall,0.6470948012232416,0.6448814343551186,-0.0022133668681230123
SentiStrengthSE,prompt_base,f1-score,0.657600635234308,0.6552318254766191,-0.002368809757688939
gemma:instruct,prompt_base,precision,0.6011023171112975,0.5977194053763976,-0.003382911734899907
gemma:instruct,prompt_base,recall,0.5951070336391437,0.5924855491329479,-0.0026214845061958147
gemma:instruct,prompt_base,f1-score,0.5925573802654817,0.5908903072627285,-0.00166707300275315
llama3:instruct,prompt_base,precision,0.6311305691108424,0.6318290230713557,0.0006984539605132678
llama3:instruct,prompt_base,recall,0.5896860986547086,0.5881365416899832,-0.0015495569647253626
llama3:instruct,prompt_base,f1-score,0.5745815845161012,0.5742356429607833,-0.0003459415553178635
mistral:instruct,prompt_base,precision,0.622527678251985,0.6247777246275169,0.0022500463755319444
mistral:instruct,prompt_base,recall,0.6244648318042814,0.6275303643724697,0.0030655325681883117
mistral:instruct,prompt_base,f1-score,0.6188890181935488,0.622633291609967,0.0037442734164182534
